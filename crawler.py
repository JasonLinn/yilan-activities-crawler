import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import logging

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_activity_details(session, activity_url):
    """ç²å–æ´»å‹•è©³ç´°è³‡è¨Šï¼ŒåŒ…æ‹¬åœ–ç‰‡"""
    try:
        response = session.get(activity_url, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        details = {}
        
        # å°‹æ‰¾æ´»å‹•åœ–ç‰‡
        images = []
        img_tags = soup.find_all('img')
        
        for img in img_tags:
            src = img.get('src', '')
            alt = img.get('alt', '')
            
            # åªæ”¶é›†ä¸Šå‚³çš„æ´»å‹•åœ–ç‰‡
            if 'upload/event/' in src:
                if src.startswith('/'):
                    full_url = f"https://yilanart.ilccb.gov.tw{src}"
                elif not src.startswith('http'):
                    full_url = f"https://yilanart.ilccb.gov.tw/{src}"
                else:
                    full_url = src
                
                images.append({
                    'url': full_url,
                    'alt': alt or 'æ´»å‹•åœ–ç‰‡'
                })
        
        details['images'] = images
        
        # å˜—è©¦ç²å–æ›´è©³ç´°çš„æ´»å‹•æè¿°
        content_div = soup.find('div', class_='content')
        if content_div:
            # å°‹æ‰¾æ´»å‹•æè¿°æ–‡å­—
            text_elements = content_div.find_all(['p', 'div'], string=True)
            description_parts = []
            for elem in text_elements:
                text = elem.get_text(strip=True)
                if len(text) > 20 and 'æ´»å‹•' in text:  # å¯èƒ½æ˜¯æ´»å‹•æè¿°
                    description_parts.append(text)
            
            if description_parts:
                details['description'] = ' '.join(description_parts[:2])  # å–å‰å…©æ®µ
        
        return details
        
    except Exception as e:
        logger.warning(f"ç²å–æ´»å‹•è©³æƒ…å¤±æ•— {activity_url}: {e}")
        return {'images': [], 'description': ''}

def crawl_yilan_activities():
    """çˆ¬å–å®œè˜­ç¸£æ–‡åŒ–å±€æ´»å‹•è³‡è¨Š"""
    url = "https://yilanart.ilccb.gov.tw/index.php?inter=activity"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        logger.info(f"é–‹å§‹çˆ¬å–: {url}")
        
        session = requests.Session()
        # å¿½ç•¥ SSL æ†‘è­‰é©—è­‰å•é¡Œ
        session.verify = False
        
        # ç¦ç”¨ SSL è­¦å‘Š
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        response = session.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # è¨­å®šæ­£ç¢ºçš„ç·¨ç¢¼
        response.encoding = 'utf-8'
        
        soup = BeautifulSoup(response.text, 'html.parser')
        logger.info("æˆåŠŸå–å¾—ç¶²é å…§å®¹")
        
        activities = []
        
        # æ ¹æ“šå¯¦éš›ç¶²é çµæ§‹èª¿æ•´é¸æ“‡å™¨
        # æ‰¾åˆ° content div
        content_div = soup.find('div', class_='content')
        
        if content_div:
            # å°‹æ‰¾æ´»å‹•é€£çµï¼Œæ’é™¤å°èˆªé€£çµ
            activity_links = content_div.find_all('a', href=True)
            
            for link in activity_links:
                href = link.get('href', '')
                text = link.get_text(strip=True)
                
                # åªè™•ç†æ´»å‹•è©³æƒ…é€£çµï¼ˆåŒ…å« did= åƒæ•¸çš„é€£çµï¼‰
                if 'did=' in href and text:
                    try:
                        activity = {}
                        
                        # è§£ææ´»å‹•æ–‡å­—ï¼Œæ ¼å¼é€šå¸¸æ˜¯ï¼šåˆ†é¡æ—¥æœŸæ¨™é¡Œåœ°é»
                        import re
                        
                        # æå–æ´»å‹•æ¨™é¡Œï¼ˆæœ€å¾Œçš„æ–‡å­—éƒ¨åˆ†ï¼‰
                        # åˆ†å‰²æ–‡å­—ï¼Œå˜—è©¦æ‰¾åˆ°æ¨¡å¼
                        parts = text.split('å…ç¥¨å…¥å ´') if 'å…ç¥¨å…¥å ´' in text else text.split('ç·šä¸Šè³¼ç¥¨') if 'ç·šä¸Šè³¼ç¥¨' in text else [text]
                        
                        if len(parts) >= 2:
                            # æœ‰ç¥¨åƒ¹è³‡è¨Š
                            activity['title'] = parts[0].strip()
                            activity['price'] = 'å…ç¥¨å…¥å ´' if 'å…ç¥¨å…¥å ´' in text else 'ç·šä¸Šè³¼ç¥¨' if 'ç·šä¸Šè³¼ç¥¨' in text else 'æœªçŸ¥'
                            activity['location'] = parts[1].strip() if len(parts) > 1 else ''
                        else:
                            # æ²’æœ‰æ˜ç¢ºçš„ç¥¨åƒ¹è³‡è¨Šï¼Œå˜—è©¦å…¶ä»–åˆ†å‰²æ–¹å¼
                            activity['title'] = text
                            activity['price'] = 'æœªçŸ¥'
                            activity['location'] = ''
                        
                        # å˜—è©¦å¾æ¨™é¡Œä¸­æå–æ—¥æœŸ
                        date_pattern = r'(\d{4})(\d{2})\.(\d{2})\.([A-Za-z]{3})'
                        date_match = re.search(date_pattern, text)
                        if date_match:
                            year, month, day, day_name = date_match.groups()
                            activity['date'] = f"{year}-{month}-{day} ({day_name})"
                            # æ¸…ç†æ¨™é¡Œï¼Œç§»é™¤æ—¥æœŸéƒ¨åˆ†
                            activity['title'] = re.sub(date_pattern, '', activity['title']).strip()
                        
                        # æå–æ´»å‹•é¡å‹ï¼ˆå¦‚æœæ–‡å­—é–‹é ­æœ‰åˆ†é¡ï¼‰
                        category_match = re.match(r'^(å±•è¦½|è¡¨æ¼”|ç ”ç¿’|æ•…äº‹|æ´»å‹•)', text)
                        if category_match:
                            activity['category'] = category_match.group(1)
                            # å¾æ¨™é¡Œä¸­ç§»é™¤åˆ†é¡
                            activity['title'] = re.sub(r'^(å±•è¦½|è¡¨æ¼”|ç ”ç¿’|æ•…äº‹|æ´»å‹•)', '', activity['title']).strip()
                        
                        # å»ºæ§‹å®Œæ•´çš„æ´»å‹•é€£çµ
                        if href.startswith('/'):
                            activity['url'] = f"https://yilanart.ilccb.gov.tw{href}"
                        elif not href.startswith('http'):
                            activity['url'] = f"https://yilanart.ilccb.gov.tw/{href}"
                        else:
                            activity['url'] = href
                        
                        # ç²å–æ´»å‹•è©³ç´°è³‡è¨Šï¼ˆåŒ…æ‹¬åœ–ç‰‡ï¼‰
                        logger.info(f"ç²å–æ´»å‹•è©³æƒ…: {activity.get('title', 'æœªçŸ¥æ´»å‹•')}")
                        details = get_activity_details(session, activity['url'])
                        activity.update(details)
                        
                        # æ·»åŠ çˆ¬å–æ™‚é–“
                        activity['crawl_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        
                        # æ¸…ç†æ¨™é¡Œä¸­çš„å¤šé¤˜å…§å®¹
                        if activity.get('title'):
                            title = activity['title']
                            # ç§»é™¤å¯èƒ½çš„åœ°é»è³‡è¨Šï¼ˆå¦‚æœåœ¨æ¨™é¡Œæœ«å°¾ï¼‰
                            locations = ['å®œè˜­æ–‡å­¸é¤¨', 'å®œè˜­ç¾è¡“é¤¨', 'ä¸­èˆˆæ–‡åŒ–å‰µæ„åœ’å€', 'é ­åŸè¦ªå­é¤¨', 
                                       'å®œè˜­æ¼”è—å»³', 'ç¾…æ±æ–‡åŒ–å·¥å ´', 'ç¾…æ±é®åœ–ä»æ„›é¤¨', 'åŒ–é¾ä¸€æ‘', 'å…¶ä»–åœ°é»']
                            for loc in locations:
                                if title.endswith(loc):
                                    title = title[:-len(loc)].strip()
                                    if not activity['location']:
                                        activity['location'] = loc
                            activity['title'] = title
                        
                        # åªæœ‰æ¨™é¡Œä¸ç‚ºç©ºæ‰åŠ å…¥
                        if activity.get('title') and len(activity['title']) > 3:
                            activities.append(activity)
                            
                    except Exception as e:
                        logger.warning(f"è§£æå–®å€‹æ´»å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        continue
        else:
            logger.warning("æœªæ‰¾åˆ°æ´»å‹•å…§å®¹å€åŸŸ")
        
        # å„²å­˜çµæœ
        output_dir = 'data'
        os.makedirs(output_dir, exist_ok=True)
        
        # å„²å­˜ç‚º JSON
        json_file = f'{output_dir}/yilan_activities_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(activities, f, ensure_ascii=False, indent=2)
        
        # å„²å­˜æœ€æ–°è³‡æ–™ (è¦†è“‹å¼)
        latest_file = f'{output_dir}/latest_activities.json'
        with open(latest_file, 'w', encoding='utf-8') as f:
            json.dump({
                'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_count': len(activities),
                'activities': activities
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æˆåŠŸçˆ¬å– {len(activities)} ç­†æ´»å‹•è³‡æ–™")
        logger.info(f"è³‡æ–™å·²å„²å­˜è‡³: {json_file}")
        
        return activities
        
    except requests.RequestException as e:
        logger.error(f"ç¶²è·¯è«‹æ±‚éŒ¯èª¤: {e}")
        raise
    except Exception as e:
        logger.error(f"çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise

def generate_readme():
    """ç”Ÿæˆ README æ–‡ä»¶é¡¯ç¤ºæœ€æ–°è³‡æ–™"""
    try:
        with open('data/latest_activities.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        readme_content = f"""# å®œè˜­ç¸£æ–‡åŒ–å±€æ´»å‹•è³‡è¨Š

## ğŸ“Š æœ€æ–°æ›´æ–°è³‡è¨Š
- **æ›´æ–°æ™‚é–“**: {data['update_time']}
- **æ´»å‹•æ•¸é‡**: {data['total_count']} ç­†

## ğŸ­ è¿‘æœŸæ´»å‹•

"""
        
        for i, activity in enumerate(data['activities'][:10], 1):  # åªé¡¯ç¤ºå‰10ç­†
            readme_content += f"### {i}. {activity.get('title', 'ç„¡æ¨™é¡Œ')}\n"
            if activity.get('date'):
                readme_content += f"- **æ™‚é–“**: {activity['date']}\n"
            if activity.get('location'):
                readme_content += f"- **åœ°é»**: {activity['location']}\n"
            if activity.get('category'):
                readme_content += f"- **é¡å‹**: {activity['category']}\n"
            if activity.get('price'):
                readme_content += f"- **ç¥¨åƒ¹**: {activity['price']}\n"
            if activity.get('url'):
                readme_content += f"- **é€£çµ**: [{activity['url']}]({activity['url']})\n"
            
            # æ·»åŠ åœ–ç‰‡
            if activity.get('images') and len(activity['images']) > 0:
                readme_content += f"- **åœ–ç‰‡**:\n"
                for img in activity['images'][:2]:  # æœ€å¤šé¡¯ç¤º2å¼µåœ–ç‰‡
                    readme_content += f"  - ![{img.get('alt', 'æ´»å‹•åœ–ç‰‡')}]({img['url']})\n"
            
            readme_content += "\n"
        
        readme_content += f"""
## ğŸ“ è³‡æ–™æª”æ¡ˆ
- [æœ€æ–°æ´»å‹•è³‡æ–™ (JSON)](./data/latest_activities.json)
- [æ­·å²è³‡æ–™ç›®éŒ„](./data/)

## ğŸ¤– è‡ªå‹•åŒ–èªªæ˜
æ­¤å°ˆæ¡ˆä½¿ç”¨ GitHub Actions æ¯å¤©è‡ªå‹•çˆ¬å–2æ¬¡è³‡æ–™ (09:00 å’Œ 21:00 UTC+8)

---
*æœ€å¾Œæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        logger.info("README.md å·²æ›´æ–°")
        
    except Exception as e:
        logger.warning(f"ç”Ÿæˆ README æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    try:
        activities = crawl_yilan_activities()
        generate_readme()
        
        print(f"âœ… çˆ¬å–å®Œæˆï¼Œå…± {len(activities)} ç­†æ´»å‹•è³‡æ–™")
        
        # é¡¯ç¤ºå‰3ç­†è³‡æ–™ä½œç‚ºé è¦½
        for i, activity in enumerate(activities[:3], 1):
            print(f"\n{i}. {activity.get('title', 'ç„¡æ¨™é¡Œ')}")
            if activity.get('date'):
                print(f"   æ™‚é–“: {activity['date']}")
            if activity.get('location'):
                print(f"   åœ°é»: {activity['location']}")
                
    except Exception as e:
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        exit(1)